TODAYDATE=$(date +'%Y%m%d')

WORKDATE=$(date +"%y%m%d") 
# slightly different

LOG_TYPE="call_events"
CALL_LOG_PATH="/home/scanner/SDRTrunk/event_logs"

LOG_DATE=$(date -d "1 day ago" '+%Y%m%d')
# Well, if I run just after midnight on a cronjob, I get what I want.

# PostgreSQL Settings
PGUSER=postgres
PGPORT=5443
PGDB=sdr


COL_NAME_LIST=${WORKDATE}_${LOG_TYPE}_column.list
# This is a generated list from the header row of the CSV, provided it has one.
# SDRTrunk call_logs happen to include a header line.

TABLE_NAME="${LOG_TYPE}_${LOG_DATE}"
# Will create a table named call_events_20230930 by day.
# This will become a pg native partitioned table or possibly using
# the TimescaleDB extension. 


COLUMN_PREFIX="l_"
# COLUMN_PREFIX - Prefix the column name found in the CSV because of possible 
# reserved/special/internal meaning column names (timestamp, grouping, public, etc).
# Another way to handle it might be to count the columns and just assign c1,c2,c3,c4,c5.
# detected column Datatype is another issue, some might be able to be figured out but 
# just defaulting to TEXT.

# Really, this is an attempt to blind create/import csv into a database... I'm sure people do this everyday
# and I could probably find something someone has created, but... meh. I have my reasons.



